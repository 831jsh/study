## 8강

### 딥러닝의 기본 개념 시작과 XOR 문제

- 생각하는 기계를 만들자
- 사람의 뇌를 연구하기 시작함
- 연결된 부분을 보니 뉴런으로 연결되어 있고 단순하게 동작함, 이렇게 단순한데 생각을 어떻게 하는지 ?
- 어떤 입력에 가중치를 두고 합쳐지고 bias를 더해 어느 정도 기준을 넘으면 활성화가 된다.
- [![deeplearnig1](https://github.com/leeplay/study/blob/master/machine-learning/image/deeplearning1.png)]()
- 기계도 할 수 있지 않을까 ?
- [![deeplearnig2](https://github.com/leeplay/study/blob/master/machine-learning/image/deeplearning2.png)]()
- logistic regression이 여기서 등장
- 인공지능 하드웨어는 예전부터 구현됨 (1960년대 전)
- and/or의 연산만 가지고 문제를 쉽게 해결할 수 있을거라 생각함
- [![deeplearnig3](https://github.com/leeplay/study/blob/master/machine-learning/image/deeplearning3.png)]()
- xor는 구분할 수 있을 ?
  - linear한 선이 나오지 않기 때문에 불가함
- [![deeplearnig4](https://github.com/leeplay/study/blob/master/machine-learning/image/deeplearning4.png)]()
- 위 문제를 해결하기 위해 Minsky 교수(MIT AI Lab)가 XOR는 현재 가진 모델로는 풀 수 없다고 증명함
- MLP를 사용하면 문제를 풀 수 있는데 학습을 시키는게 불가능하다 함
- [![deeplearnig5](https://github.com/leeplay/study/blob/master/machine-learning/image/deeplearning5.png)]()
- [![deeplearnig6](https://github.com/leeplay/study/blob/master/machine-learning/image/deeplearning6.png)]()
- 이 이론을 본 사람들은 안되는 걸로 받아들이지만 1982년에 이 문제가 해결됨, 그런데 주목받지 못 함
  - Backpropagation 알고리즘
- [![deeplearning7](https://github.com/leeplay/study/blob/master/machine-learning/image/deeplearning7.png)]()
- 86년도에 Hinton이 같은 이론으로 주목을 받음
- 다른 교수가 다른 접근법을 들고
  - 고양이를 가지고 분석함
  - 그림을 볼 때 전체를 보는게 아니라 일부를 보고 조합해서 전체를 본다는 걸 알아냄
  - 굉장히 잘 동작함, 미국에서는 1990년대에 책을 기계가 다 읽어들임, 자율주행차도 만듦
- [![deeplearning8](https://github.com/leeplay/study/blob/master/machine-learning/image/deeplearning8.png)]()
- [![deeplearning9](https://github.com/leeplay/study/blob/master/machine-learning/image/deeplearning9.png)]()
- 더 큰 문제가 등장함
  - 레이어가 너무 많기 때문에 Backpropagation으로는 레이어 학습이 너무 복잡함
  - 다시 뉴럴네트웍은 침체기로 접어듬
- [![deeplearning10](https://github.com/leeplay/study/blob/master/machine-learning/image/deeplearning10.png)]()
- Hinton은 뉴럴네트웍 침체기에 캐나라도 이민을 가게되고 CIFAR 연구소에서 후원해 줌


### Back-propagation과 2006/2007 딥의 출현

- Hinton은 뉴럴네트웍 침체기에 캐나라도 이민을 가게되고 CIFAR 연구소에서 후원해 줌
- 2006 ~ 07년에 breakthrough 하는 두 개의 주요 논문이 나옴
- 초기 weight 값을 잘주면 복잡한 문제를 풀 수 있다고 주장함
- 뉴럴 네트웍은 너무 불신이 커서 이때 새로운 용어를 만듬 그게 Deep Nets, Deep learnig 이다.
- imagenet이란 대회가 있는데 image를 조합해 어떤 이미지인지 판단하는 알고리즘 대회가 있음
- 이 대회에서 hinton 교수 연구실 알렉스란 박사가 에러율을 26.2 -> 15.3% 로 낮추고 주목을 받음 (현재 3% 에러율, 아주 뛰어난 사람이 5%)
- 그림의 label 뿐만 아니라 그림 설명도 가능함
- 프로그래밍을 말로도 하게 만들고 있음 (현재 정확도 70%)
- [![deeplearning11](https://github.com/leeplay/study/blob/master/machine-learning/image/deeplearning11.png)]()
- 음성인식/게임자동호/알파고에도 쓰임
